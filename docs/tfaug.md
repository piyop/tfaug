<a id="tfaug"></a>

# tfaug

@license: MIT
@author: t.okuda

<a id="tfaug.DatasetCreator"></a>

## DatasetCreator Objects

```python
class DatasetCreator()
```

The creator of tf.data.Dataset

if create dataset from tfrecord files, use dataset_from_tfrecords()
else if create dataset from image filepaths, use dataset_from_path()

dataset_from_tfrecords() can adjust sampling ratios by specifying ratio_samples

<a id="tfaug.DatasetCreator.__init__"></a>

#### \_\_init\_\_

```python
 | __init__(shuffle_buffer: int, batch_size: int, label_type: str = None, repeat: bool = False, preproc: Callable = None, augmentation: bool = True, **kwargs: dict)
```

creator for tf.data.dataset


**Arguments**:

- `shuffle_buffer` _int_ - shuffle buffer size. if you don't need shuffle, use shuffle_buffer=None.
- `batch_size` _int_ - batch size..
- `label_type` _str, optional_ - 'segmentation' or 'class'.
  automatically load from json file after ver.0.1.0.5.
  Defaults to None.
- `repeat` _bool, optional_ - repeat every datasets or use once. Defaults to False.
- `preproc` _Callable, optional_ - preprocess callback function before augment image. The default is None
  proprocess function must take (img, label) and return (img, label). Defaults to None.
- `augmentation` _bool, optional_ - use argmentation or not.
  Defaults to True.
- `**kwargs` _dict_ - augmentation parameters.
  These parameters directly pass to the AugmentImg().
  Refer AugmentImg.__init__() to see the parameter descriptions
  

**Returns**:

  None.

<a id="tfaug.DatasetCreator.dataset_from_path"></a>

#### dataset\_from\_path

```python
 | dataset_from_path(img_paths: List[str], labels: Union[List[str], List[int], np.ndarray] = None, imgtype: str = 'png') -> tf.data.Dataset
```

create dataset from filepaths


**Arguments**:

- `img_paths` _List[str]_ - source image paths.
- `labels` _Union[List[str], List[int], np.ndarray], optional_ - filepaths or values of labels. Defaults to None.
- `imgtype` _str, optional_ - 'png' or 'jpg'. Defaults to 'png'.
  

**Raises**:

- `NotImplementedError` - if image type is not in (png, jpg).
  

**Returns**:

- `dataset` _tf.data.Dataset_ - dataset iterator.

<a id="tfaug.DatasetCreator.dataset_from_tfrecords"></a>

#### dataset\_from\_tfrecords

```python
 | dataset_from_tfrecords(path_tfrecords: Union[List[str], List[List[str]]], ratio_samples: List[float] = None) -> Tuple[tf.data.Dataset, int]
```

create dataset from tfrecords


**Arguments**:

- `path_tfrecords` _Union[List[str], List[List[str]]]_ - paths to tfrecords
  generated by TfrecordConverter.
- `ratio_samples` _List[float], optional_ - the sampling ratios from path_tfrecords.
  if use ratio_samples, path_tfrecord must be a 2-d list of tfrecord paths.
  Defaults to None.
  

**Returns**:

- `dataset` _tf.data.Dataset_ - dataset iterator.
- `num_img` _int_ - the number of images in all tfrecord files.

<a id="tfaug.check_label_type"></a>

#### check\_label\_type

```python
check_label_type(labels: Union[List[int],List[str],np.ndarray]) -> str
```

check label type in labels[0]


**Arguments**:

- `labels` _Union[List[int],List[str],np.ndarray]_ - label data source..
  

**Returns**:

- `label_type` _str_ - 'segmentation' or 'class'.

<a id="tfaug.TfrecordConverter"></a>

## TfrecordConverter Objects

```python
class TfrecordConverter()
```

The converter of images to tfrecords

If you would like to generate tfrecord from image filepaths, 
use tfrecord_from_path_label()
else if you would like to generate tfrecord from array or list, 
use tfrecord_from_ary_label()

If your images are not aligned width and height, you should resize or crop
images to the same size for learning.
split_to_patch() support that use case when split large images.

<a id="tfaug.TfrecordConverter.__init__"></a>

#### \_\_init\_\_

```python
 | __init__()
```

The converter of images to tfrecords

**Returns**:

  None.

<a id="tfaug.TfrecordConverter.tfrecord_from_path_label"></a>

#### tfrecord\_from\_path\_label

```python
 | tfrecord_from_path_label(path_imgs: List[str], labels: Union[List[str], List[int], np.ndarray], path_out: str, image_per_shard: int = None)
```

Convert from image paths


**Arguments**:

- `path_imgs` _List[str]_ - paths to images.
- `labels` _Union[List[str], List[int], np.ndarray]_ - if segmentation, path to the label images
  else if classification, int class labels.
- `path_out` _str_ - output path.
- `image_per_shard` _int, optional_ - the number of images when split
  images to shards. Defaults to None.
  

**Returns**:

  None.

<a id="tfaug.TfrecordConverter.tfrecord_from_ary_label"></a>

#### tfrecord\_from\_ary\_label

```python
 | tfrecord_from_ary_label(ary: Union[List[np.ndarray], np.ndarray], labels: Union[List[int], List[np.ndarray], np.ndarray], path_out: str, image_per_shard: int = None)
```

Convert from image arrays


**Arguments**:

- `ary` _Union[List[np.ndarray], np.ndarray]_ - image array.
- `labels` _Union[List[np.ndarray], np.ndarray]_ - if segmentation, label image array
  else if classification, integer class labels.
- `path_out` _str_ - output path.
- `image_per_shard` _int, optional_ - the number of images when split
  images to shards. Defaults to None.
  

**Returns**:

  None.

<a id="tfaug.TfrecordConverter.split_to_patch"></a>

#### split\_to\_patch

```python
 | split_to_patch(npimg: np.ndarray, patch_size: Union[int, Tuple[int, int]], buffer_size: Union[int, Tuple[int, int]], dtype: np.dtype = np.uint8) -> np.ndarray
```

split images to patch


**Arguments**:

- `npimg` _np.ndarray_ - input 3-d image.
- `patch_size` _Union[int, Tuple[int, int]]_ - patch size to split.
- `buffer_size` _Union[int, Tuple[int, int]]_ - overlap buffer size.
- `dtype` _np.dtype, optional_ - output dtype. Defaults to np.uint8.
  

**Returns**:

  4-d np.ndarray: each splitted images are packed into first of the 4 dimension.

<a id="tfaug.TfrecordConverter.get_patch"></a>

#### get\_patch

```python
 | get_patch(npimg: np.ndarray, patch_size: Union[int, Tuple[int, int]], buffer_size: Union[int, Tuple[int, int]], xx: List[int], yy: List[int], dtype: np.dtype = np.uint8)
```

**Arguments**:

- `npimg` _np.ndarray_ - input 3-d image.
- `patch_size` _Union[int, Tuple[int, int]]_ - patch size to split.
- `buffer_size` _Union[int, Tuple[int, int]]_ - overlap buffer size.
- `xx` _List[int]_ - x-axis to split the point.
- `yy` _List[int]_ - y-axis to split the point.
- `dtype` _np.dtype, optional_ - dtype. Defaults to np.uint8.
  

**Returns**:

  4-d np.ndarray : each splitted images are packed into first of the 4 dimension.

<a id="tfaug.AugmentImg"></a>

## AugmentImg Objects

```python
class AugmentImg()
```

image augmentation class for tf.data

set augmentation parameters in __int__() then call it directly or
in tf.data.Dataset.map()

<a id="tfaug.AugmentImg.__init__"></a>

#### \_\_init\_\_

```python
 | __init__(standardize: bool = False, resize: Tuple[int, int] = None, random_rotation: float = 0, random_flip_left_right: bool = False, random_flip_up_down: bool = False, random_shift: Tuple[float, float] = None, random_zoom: Tuple[float, float] = None, random_shear: Tuple[float, float] = None, random_brightness: float = None, random_saturation: Tuple[float, float] = None, random_hue: float = None, random_contrast: Tuple[float, float] = None, random_crop: Tuple[int, int] = None, central_crop: Tuple[int, int] = None, random_noise: float = None, random_blur: float = None, random_blur_kernel: float = 3, interpolation: str = 'nearest', clslabel: bool = False, dtype: type = None, input_shape: Tuple[int, int, int, int] = None, input_shape_label: Tuple[int, int, int, int] = None, num_transforms: int = 10000, training: bool = False) -> Callable[[tf.Tensor, tf.Tensor], Tuple[tf.Tensor, tf.Tensor]]
```

__init__() sets the parameters for augmantation.

__call__() can take not only input image but also label image.
Image and label image will be augmented with the same transformation at the same time.
However, label image is not augmented by random_brightness, random_saturation, standardize

This augmentation is executed on a batch of images.
Input image should be 4d Tensor(batch, x, y, channel)
The image sizes are presumed to be the same on each image when

If training == False, this class will not augment images except standardize,
resize, random_crop or central_crop.


**Arguments**:

- `standardize` _bool, optional_ - image standardization.
  if true, returned image dtype will be float automatically.
  Defaults to False.
- `resize` _Tuple[int, int], optional_ - specify resize image size [y_size, x_size]
  this resize operation is done before below augmentations. Defaults to None.
- `random_rotation` _float, optional_ - maximum rotation angle(degree).
  Defaults to 0.
- `random_flip_left_right` _bool, optional_ - Defaults to False.
- `random_flip_up_down` _bool, optional_ - Defaults to False.
- `random_shift` _Tuple[float, float], optional_ - maximum shift ratios of images.
  vartical shift ratio: (-list[0], list[0])
  holizontal shift ratio: (-list[1], list[1])
  Defaults to None.
  random_zoom (Tuple[float, float], optional):random zoom ratios of an image. unit is width and height retios.
  random_zoom[0] is y-direction, random_zoom[1] is x-direction.
  Defaults to None.
- `random_shear` _Tuple[float, float], optional_ - randomly shear of image. unit is degree.
  random_shear[0] is y-direction(degrees), random_shear[1] is x-direction(degrees).
  Defaults to None.
- `random_brightness` _float, optional_ - maximum image delta brightness range [-random_brightness, random_brightness).
  The value delta is added to all components of the tensor image.
  image is converted to float and scaled appropriately
  if it is in fixed-point representation, and
  delta is converted to the same data type.
  For regular images, delta should be in the range (-1,1),
  as it is added to the image in floating point representation,
  where pixel values are in the [0,1) range.
  Defaults to None.
- `random_saturation` _Tuple[float, float], optional_ - maximum image saturation factor range between [random_saturation[0],
  random_saturation[1]).
  The value saturation factor is multiplying to the saturation channel of images.
  Defaults to None.
- `random_hue` _float, optional_ - maximum delta hue of RGB images between [-random_hue, random_hue).
  max_delta must be in the interval [0, 0.5].
  Defaults to None.
- `random_contrast` _Tuple[float, float], optional_ - randomly adjust contrast of RGB images by contrast factor
  which lies between [random_contrast[0], random_contrast[1])
  result image is calculated by (x - mean) * contrast_factor + mean.
  Defaults to None.
- `random_crop` _Tuple[int, int], optional_ - randomly crop image with size [height,width] = [random_crop[0], random_crop[1]].
  Defaults to None.
- `central_crop` _Tuple[int, int], optional_ - crop center of image with size [height,width] = [central_crop[0], central_crop[1]].
  Defaults to None.
- `random_noise` _float, optional_ - add random gaussian noise.
  random_noise value means sigma param of gaussian.
  Defaults to None.
- `random_blur` _float, optional_ - add random gaussian blur. the value means sigma param of gaussian.
  random_blur generate sigma as uniform(0, random_blur) for every mini-batch
  random blur converts integer images to float images. Defaults to None.
- `random_blur_kernel` _float, optional_ - kernel size of gaussian random blur.
  Defaults to 3.
- `interpolation` _str, optional_ - interpolation method. nearest or bilinear
  Defaults to 'nearest'.
- `clslabel` _bool, optional_ - If false, labels are presumed to be the same dimensions as the image and
  apply the same geometric transformations to labels. Defaults to False.
- `dtype` _type, optional_ - tfaug cast input images to this dtype after
  geometric transformation.
  Defaults to None.
- `input_shape` _Tuple[int, int, int, int], optional_ - input image (batch,y,x,channels) dimensions.
  To reduce CPU load by generating all transform matrices at first,
  use this. Defaults to None.
- `input_shape_label` _Tuple[int, int, int, int], optional_ - input label (batch,y,x,channels) dimensions.
  To reduce CPU load by generating all transform matrices at first,
  use this if label is segmentation. Defaults to None.
- `num_transforms` _int, optional_ - The number of transformation matrixes generated in advance.
  when input_shape is used. Defaults to 10,000.
- `training` _bool, optional_ - If false, augment is not done except standardize.
  Defaults to False.
  

**Returns**:

  callable object (Callable[[tf.Tensor, tf.Tensor], Tuple[tf.Tensor, tf.Tensor]]) : class instance

<a id="tfaug.AugmentImg.__call__"></a>

#### \_\_call\_\_

```python
 | @tf.function
 | __call__(image: tf.Tensor, label: tf.Tensor = None) -> Tuple[tf.Tensor, tf.Tensor]
```

call function of AugmentImg


**Arguments**:

- `image` _tf.Tensor_ - 4d tf.Tensor (batch, x, y, channel).
- `label` _tf.Tensor, optional_ - 4d or 1d tf.Tensor (batch, x, y, channel), optional.
  Defaults to None.
  

**Returns**:

  Tuple[tf.Tensor, tf.Tensor]: augmented images and labels.

